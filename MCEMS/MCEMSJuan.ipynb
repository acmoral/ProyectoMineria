{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal_length', ' sepal_width', ' petal_length', ' petal width',\n",
      "       'class'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length   sepal_width   petal_length   petal width           class\n",
       "0             5.1           3.5            1.4           0.2     Iris-setosa\n",
       "1             4.9           3.0            1.4           0.2     Iris-setosa\n",
       "2             4.7           3.2            1.3           0.2     Iris-setosa\n",
       "3             4.6           3.1            1.5           0.2     Iris-setosa\n",
       "4             5.0           3.6            1.4           0.2     Iris-setosa\n",
       "..            ...           ...            ...           ...             ...\n",
       "145           6.7           3.0            5.2           2.3  Iris-virginica\n",
       "146           6.3           2.5            5.0           1.9  Iris-virginica\n",
       "147           6.5           3.0            5.2           2.0  Iris-virginica\n",
       "148           6.2           3.4            5.4           2.3  Iris-virginica\n",
       "149           5.9           3.0            5.1           1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importar el dataset\n",
    "iris = pd.read_csv('./iris.csv')\n",
    "print(iris.keys())\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\juanc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\juanc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\juanc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\juanc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\juanc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.23.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\juanc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in c:\\users\\juanc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scipy) (1.23.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\juanc\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.stats import entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32),\n",
       " array([18, 18, 19, 19, 18, 22, 19, 18, 19, 18, 22, 23, 18, 19, 21, 21, 21,\n",
       "        18, 22, 23, 22, 23, 19, 23, 23, 18, 23, 18, 18, 18, 18, 22, 21, 21,\n",
       "        18, 18, 22, 18, 19, 18, 18, 20, 19, 23, 23, 18, 23, 19, 22, 18, 11,\n",
       "        12, 11, 15, 11, 14, 12, 13, 11, 15, 13, 14, 16, 12, 15, 11, 14, 14,\n",
       "        10, 15,  8, 14,  9, 12, 12, 11, 11, 11, 12, 15, 15, 15, 14,  9, 14,\n",
       "        12, 11, 10, 14, 15, 14, 12, 14, 13, 14, 14, 14, 12, 13, 14,  5,  8,\n",
       "         1,  7,  7,  2, 17,  1,  7,  4,  6,  9,  6,  8,  8,  6,  7,  3,  2,\n",
       "        10,  5,  8,  2,  9,  5,  1,  9,  8,  7,  1,  1,  3,  7,  9,  9,  4,\n",
       "         5,  7,  8,  6,  5,  6,  8,  5,  5,  6,  9,  6,  5,  8],\n",
       "       dtype=int32),\n",
       " array([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,\n",
       "         2,  2,  2,  2,  2,  2,  2,  3,  2,  2,  2,  2,  2,  2,  2,  2,  8,\n",
       "         8,  8,  9,  8,  9,  8,  7,  8,  9,  7,  9,  9,  8,  9,  8,  9,  9,\n",
       "         8,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  8,  9,\n",
       "         8,  8,  8,  9,  9,  9,  8,  9,  7,  9,  9,  9,  8,  7,  9,  4,  8,\n",
       "         6,  4,  4,  6, 10,  6,  4,  5,  4,  4,  4,  8,  8,  4,  4,  5,  6,\n",
       "         8,  4,  8,  6,  8,  4,  6,  8,  8,  4,  6,  6,  5,  4,  8,  4,  6,\n",
       "         4,  4,  8,  4,  4,  4,  8,  4,  4,  4,  8,  4,  4,  8],\n",
       "       dtype=int32),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 3, 6, 4, 3, 3, 4, 7, 4, 3, 4,\n",
       "        3, 3, 3, 6, 6, 3, 3, 4, 4, 6, 3, 6, 4, 6, 3, 4, 6, 6, 3, 4, 4, 4,\n",
       "        3, 6, 3, 4, 3, 3, 6, 3, 3, 3, 6, 3, 3, 3, 6, 3, 3, 6], dtype=int32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Importamos el dataset\n",
    "df = pd.read_csv('./iris.csv')\n",
    "\n",
    "# Selecciona las características para el clustering\n",
    "data = df[['sepal_length', ' sepal_width', ' petal_length', ' petal width']].values\n",
    "\n",
    "\n",
    "# Método de enlace: Single linkage\n",
    "def single_linkage_clustering(data):\n",
    "    linkage_matrix = linkage(data, method='single', metric='euclidean')\n",
    "    labels = fcluster(linkage_matrix, t=1.0, criterion='distance')\n",
    "    return labels\n",
    "\n",
    "# Método de enlace: Complete linkage\n",
    "def complete_linkage_clustering(data):\n",
    "    linkage_matrix = linkage(data, method='complete', metric='euclidean')\n",
    "    labels = fcluster(linkage_matrix, t=1.0, criterion='distance')\n",
    "    return labels\n",
    "\n",
    "# Método de enlace: Average linkage\n",
    "def average_linkage_clustering(data):\n",
    "    linkage_matrix = linkage(data, method='average', metric='euclidean')\n",
    "    labels = fcluster(linkage_matrix, t=1.0, criterion='distance')\n",
    "    return labels\n",
    "\n",
    "# Método de enlace: Centroid linkage\n",
    "def centroid_linkage_clustering(data):\n",
    "    # Calcula las distancias euclidianas entre los puntos\n",
    "    pairwise_dist = pdist(data, metric='euclidean')\n",
    "    linkage_matrix = linkage(pairwise_dist, method='centroid')\n",
    "    labels = fcluster(linkage_matrix, t=1.0, criterion='distance')\n",
    "    return labels\n",
    "\n",
    "# Aplica los métodos de clustering y almacena los resultados en clustering_results\n",
    "single_linkage_result = single_linkage_clustering(data)\n",
    "complete_linkage_result = complete_linkage_clustering(data)\n",
    "average_linkage_result = average_linkage_clustering(data)\n",
    "centroid_linkage_result = centroid_linkage_clustering(data)\n",
    "\n",
    "# Almacena los resultados en el DataFrame original\n",
    "# Contiene las etiquetas de clústeres para los cuatro métodos de enlace.\n",
    "clustering_results = [single_linkage_result, complete_linkage_result, average_linkage_result, centroid_linkage_result]\n",
    "clustering_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropía de Shannon: [-127.88196256 -193.91402739  -18.28421252  -30.85531138   -7.55324985\n",
      "  -80.1677942    -6.16775862  -42.52096249  -24.43401072   -3.30482024\n",
      "   -6.6457682    -7.38721876   -5.52642908  -12.65148445   -9.15083973\n",
      "   -7.5          -8.37171708  -20.4423182   -13.30998694  -11.10964047\n",
      "  -12.96207659  -14.93974502  -17.1428125 ]\n"
     ]
    }
   ],
   "source": [
    "def calculate_diversity(clustering_results):\n",
    "    m = len(clustering_results)\n",
    "    diversities = []\n",
    "    for i in range(m):\n",
    "        diversity_sum = 0\n",
    "        for j in range(m):\n",
    "            if i != j:\n",
    "                # Calcula la entropía de Shannon para los resultados de clustering i y j\n",
    "                entropy_i = calculate_shannons_entropy(clustering_results[i])\n",
    "                entropy_j = calculate_shannons_entropy(clustering_results[j])\n",
    "                \n",
    "                # Calcula la diferencia entre las entropías de Shannon y acumula la diversidad\n",
    "                diversity_sum += np.linalg.norm(entropy_i - entropy_j)\n",
    "        \n",
    "        # Calcula el promedio de las diferencias de entropías para obtener la diversidad\n",
    "        diversity = diversity_sum / m\n",
    "        diversities.append(diversity)\n",
    "    return diversities\n",
    "\n",
    "\n",
    "\n",
    "# Función para calcular la entropía de Shannon según la fórmula del texto\n",
    "def calculate_shannons_entropy(labels):\n",
    "    label_counts = np.unique(labels, return_counts=True)\n",
    "    total_instances = len(labels)\n",
    "    \n",
    "    entropy = 0\n",
    "    for count in label_counts:\n",
    "        probability = count / total_instances\n",
    "        entropy -= probability * np.log2(probability)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "entropy_value = calculate_shannons_entropy(clustering_results)\n",
    "print(\"Entropía de Shannon:\", entropy_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61.48742946988651, 109.73641414287104, 52.41410700640461, 50.085144087496474]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Cálculo de w_k^1 (diversidad) y w_k^2 (calidad) para cada método\n",
    "m = len(clustering_results)\n",
    "w_k_1 = []\n",
    "w_k_2 = []\n",
    "\n",
    "# # Cálculo de w_k^1 - Diversidad\n",
    "# for i in range(m):\n",
    "#     diversity_sum = 0\n",
    "#     for j in range(m):\n",
    "#         if i != j:\n",
    "#             # Calcula la diversidad utilizando la entropía de Shannon\n",
    "#             diversity_sum += entropy(np.histogram(clustering_results[i], bins=len(set(clustering_results[i])))[0],\n",
    "#                                      np.histogram(clustering_results[j], bins=len(set(clustering_results[j])))[0])\n",
    "#     w_k_1.append(diversity_sum / m)\n",
    "\n",
    "# Calcula la diversidad (peso w_k^1) entre los métodos\n",
    "def calculate_diversity(clustering_results):\n",
    "    m = len(clustering_results)\n",
    "    diversities = []\n",
    "    for i in range(m):\n",
    "        diversity_sum = 0\n",
    "        for j in range(m):\n",
    "            if i != j:\n",
    "                # Calcula la diversidad usando la entropía de Shannon\n",
    "                diversity_sum += np.linalg.norm(np.array(clustering_results[i]) - np.array(clustering_results[j]))\n",
    "        diversity = diversity_sum / m\n",
    "        diversities.append(diversity)\n",
    "    return diversities\n",
    "\n",
    "diversity_scores = calculate_diversity(clustering_results)\n",
    "diversity_scores\n",
    "\n",
    "# # Cálculo de w_k^2\n",
    "# for result in clustering_results:\n",
    "#     inter_cluster_distance = 0\n",
    "#     intra_cluster_distance = 0\n",
    "#     for cluster_label in set(result):\n",
    "#         cluster_points = np.array([data[i] for i in range(len(result)) if result[i] == cluster_label])\n",
    "#         # Calcula la distancia intra-cluster como la suma de las distancias euclidianas entre los puntos en el cluster\n",
    "#         intra_cluster_distance += np.sum(np.linalg.norm(cluster_points - np.mean(cluster_points, axis=0), axis=1))\n",
    "#         # Calcula la distancia inter-cluster como la suma de las distancias euclidianas entre los centroides de los clusters\n",
    "#         for other_cluster_label in set(result):\n",
    "#             if cluster_label != other_cluster_label:\n",
    "#                 other_cluster_points = np.array([data[i] for i in range(len(result)) if result[i] == other_cluster_label])\n",
    "#                 inter_cluster_distance += np.linalg.norm(np.mean(cluster_points, axis=0) - np.mean(other_cluster_points, axis=0))\n",
    "\n",
    "#     w_k_2.append(inter_cluster_distance / intra_cluster_distance)\n",
    "\n",
    "# # Selecciona el subconjunto óptimo P* usando el criterio de selección\n",
    "# rho = 0.35\n",
    "# combined_scores = np.array(w_k_1) * np.array(w_k_2)\n",
    "# sorted_methods = np.argsort(combined_scores)[::-1]\n",
    "# selected_indices = sorted_methods[:int(rho * m)]\n",
    "# P_star = [clustering_results[i] for i in selected_indices]\n",
    "\n",
    "# P_star\n",
    "\n",
    "# Ahora P_star contiene las etiquetas de clústeres del subconjunto óptimo de métodos para el agrupamiento en conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de métodos de agrupamiento\n",
    "m = len(clustering_results)\n",
    "\n",
    "# Calcula la diversidad (peso w_k^1) entre los métodos\n",
    "def calculate_diversity(results):\n",
    "    diversities = []\n",
    "    for i in range(m):\n",
    "        diversity_sum = 0\n",
    "        for j in range(m):\n",
    "            if i != j:\n",
    "                diversity_sum += np.linalg.norm(np.array(results[i]) - np.array(results[j]))\n",
    "        diversity = diversity_sum / m\n",
    "        diversities.append(diversity)\n",
    "    return diversities\n",
    "\n",
    "diversity_scores = calculate_diversity(clustering_results)\n",
    "\n",
    "# Calcula la calidad (peso w_k^2) de los métodos\n",
    "def calculate_quality(results):\n",
    "    quality_scores = []\n",
    "    for result in results:\n",
    "        # Calcula la distancia intra-cluster y inter-cluster (puedes usar métricas como la distancia Euclidiana)\n",
    "        intra_cluster_distance = calculate_intra_cluster_distance(result)\n",
    "        inter_cluster_distance = calculate_inter_cluster_distance(result)\n",
    "        quality = inter_cluster_distance / intra_cluster_distance\n",
    "        quality_scores.append(quality)\n",
    "    return quality_scores\n",
    "\n",
    "def calculate_intra_cluster_distance(labels):\n",
    "    # Implementa la lógica para calcular la distancia intra-cluster\n",
    "    pass\n",
    "\n",
    "def calculate_inter_cluster_distance(labels):\n",
    "    # Implementa la lógica para calcular la distancia inter-cluster\n",
    "    pass\n",
    "\n",
    "quality_scores = calculate_quality(clustering_results)\n",
    "\n",
    "# Calcula el puntaje combinado (diversidad * calidad) para cada método\n",
    "combined_scores = [diversity_scores[i] * quality_scores[i] for i in range(m)]\n",
    "\n",
    "# Ordena los métodos según el puntaje combinado en orden descendente\n",
    "sorted_methods = sorted(range(m), key=lambda k: combined_scores[k], reverse=True)\n",
    "\n",
    "# Porcentaje de métodos a seleccionar\n",
    "rho = 0.35\n",
    "\n",
    "# Selecciona los primeros rho por ciento de los métodos para formar P*\n",
    "selected_methods = sorted_methods[:int(rho * m)]\n",
    "\n",
    "# Los métodos seleccionados están en la lista selected_methods\n",
    "print(\"Métodos seleccionados:\", selected_methods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
