{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from scipy.stats import trim_mean\n",
    "from numpy import mean, absolute\n",
    "import random\n",
    "\n",
    "data = pd.read_csv('../data/weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances = 71382\n",
      "Number of attributes = 23\n",
      "---------------------------------------------------\n",
      "\n",
      "Number of missing values:\n",
      "\tDate: 0 missing (0.000%) object\n",
      "\tLocation: 0 missing (0.000%) object\n",
      "\tMinTemp: 617 missing (0.864%) float64\n",
      "\tMaxTemp: 589 missing (0.825%) float64\n",
      "\tRainfall: 911 missing (1.276%) float64\n",
      "\tEvaporation: 0 missing (0.000%) float64\n",
      "\tSunshine: 0 missing (0.000%) float64\n",
      "\tWindGustDir: 4351 missing (6.095%) object\n",
      "\tWindGustSpeed: 4328 missing (6.063%) float64\n",
      "\tWindDir9am: 2617 missing (3.666%) object\n",
      "\tWindDir3pm: 718 missing (1.006%) object\n",
      "\tWindSpeed9am: 215 missing (0.301%) float64\n",
      "\tWindSpeed3pm: 432 missing (0.605%) float64\n",
      "\tHumidity9am: 913 missing (1.279%) float64\n",
      "\tHumidity3pm: 1089 missing (1.526%) float64\n",
      "\tPressure9am: 653 missing (0.915%) float64\n",
      "\tPressure3pm: 660 missing (0.925%) float64\n",
      "\tCloud9am: 7052 missing (9.879%) float64\n",
      "\tCloud3pm: 8581 missing (12.021%) float64\n",
      "\tTemp9am: 652 missing (0.913%) float64\n",
      "\tTemp3pm: 847 missing (1.187%) float64\n",
      "\tRainToday: 911 missing (1.276%) object\n",
      "\tRainTomorrow: 964 missing (1.350%) object\n"
     ]
    }
   ],
   "source": [
    "# Crear una copia del DataFrame con las columnas deseadas\n",
    "df_copia = data.copy()\n",
    "\n",
    "\n",
    "df_sin_nulos = df_copia.dropna(subset=['Sunshine'])\n",
    "df_sin_nulos = df_sin_nulos.dropna(subset=['Evaporation'])\n",
    "\n",
    "\n",
    "print('Number of instances = %d' % (df_sin_nulos.shape[0]))\n",
    "print('Number of attributes = %d' % (df_sin_nulos.shape[1]))\n",
    "print('---------------------------------------------------\\n')\n",
    "print('Number of missing values:')\n",
    "for col in df_sin_nulos.columns:\n",
    "    num_missing = df_sin_nulos[col].isna().sum()\n",
    "    percentage_missing = (num_missing / df_sin_nulos.shape[0]) * 100\n",
    "    print('\\t%s: %d missing (%.3f%%) %s' % (col, num_missing, percentage_missing, df_sin_nulos[col].dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo las columnas numéricas\n",
    "columnas_numericas = data.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Agregar la columna categórica 'RainTomorrow'\n",
    "columnas_a_incluir = list(columnas_numericas) + ['RainTomorrow']\n",
    "\n",
    "# Crear una copia del DataFrame con las columnas deseadas\n",
    "df_copia = data[columnas_a_incluir].copy()\n",
    "\n",
    "# df_sin_nulos = df_copia.dropna(subset=['Sunshine'])\n",
    "# df_sin_nulos = df_sin_nulos.dropna(subset=['Evaporation'])\n",
    "\n",
    "df_sin_nulos =df_copia\n",
    "\n",
    "withNullColumn = []\n",
    "\n",
    "df_sin_nulos = df_sin_nulos.replace('NA', np.NaN)\n",
    "\n",
    "\n",
    "for col in df_sin_nulos.columns:\n",
    "    num_missing = df_sin_nulos[col].isna().sum()\n",
    "    percentage_missing = (num_missing / df_sin_nulos.shape[0]) * 100\n",
    "    print('\\t%s: %d missing (%.3f%%) %s' % (col, num_missing, percentage_missing, df_sin_nulos[col].dtype))\n",
    "    if num_missing > 0:\n",
    "        withNullColumn.append((col))\n",
    "\n",
    "# Iterar sobre las columnas con valores nulos\n",
    "for col in withNullColumn:\n",
    "    if df_sin_nulos[col].dtype == 'float64':\n",
    "        # Reemplazar valores nulos en columnas float64 con la mediana de la columna\n",
    "        median = df_sin_nulos[col].mean()\n",
    "        df_sin_nulos[col].fillna(median, inplace=True)\n",
    "    # # elif df_sin_nulos[col].dtype == 'object':\n",
    "    # else:\n",
    "    #     # Reemplazar valores nulos en columnas object con la moda de la columna\n",
    "    #     mode = df_sin_nulos[col].mode()\n",
    "    #     print('mode on col', col, mode[0])\n",
    "    #     df_sin_nulos[col].fillna(mode[0], inplace=True)\n",
    "\n",
    "withNullColumn = []\n",
    "\n",
    "data2 = data.replace('NA', np.NaN)\n",
    "\n",
    "print('Number of instances = %d' % (data2.shape[0]))\n",
    "print('Number of attributes = %d' % (data2.shape[1]))\n",
    "print('---------------------------------------------------\\n')\n",
    "print('Number of missing values:')\n",
    "for col in data2.columns:\n",
    "    num_missing = data2[col].isna().sum()\n",
    "    percentage_missing = (num_missing / data2.shape[0]) * 100\n",
    "    print('\\t%s: %d missing (%.3f%%) %s' % (col, num_missing, percentage_missing, data2[col].dtype))\n",
    "    if num_missing > 0:\n",
    "        withNullColumn.append((col))\n",
    "\n",
    "\n",
    "print(data.shape)\n",
    "print(df_sin_nulos.shape)\n",
    "\n",
    "\n",
    "#ranking de variables --------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Sacar las medias y las varianzas\n",
    "means = df_sin_nulos.groupby(\"RainTomorrow\").mean()\n",
    "variances = df_sin_nulos.groupby(\"RainTomorrow\").var()\n",
    "\n",
    "# Calcular la diferencia absoluta entre los medias de RainTomorrow\n",
    "dif_means = (means.loc[\"No\"] - means.loc[\"Yes\"]).abs()\n",
    "\n",
    "# Calcular la diferencia absoluta entre las varianzas de RainTomorrow\n",
    "dif_var = (variances.loc[\"No\"] - variances.loc[\"Yes\"]).abs()\n",
    "\n",
    "rank_means = dif_means.rank(ascending=False) #Se de deja ascending=False ya que queremos que las diferencias más altas ocupen los primeros lugars\n",
    "rank_var = dif_var.rank()\n",
    "\n",
    "#unir los dos rankings y calcular el ranking final para cada dimensión\n",
    "final_rank = ((rank_means + rank_var) /2).rank().sort_values()\n",
    "\n",
    "print(\"Ranking de importancia de las dimensiones:\")\n",
    "print(final_rank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
